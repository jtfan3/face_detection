{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import modules.mod_faceDetection as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate facedetection model\n",
    "face_detector = fd.FaceDetection(model_selection = 0, threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(bbox_dict, frame):\n",
    "    x_min, y_min, w, h = bbox_dict.values()\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    # get centerpoint\n",
    "    center_w = x_min + w/2\n",
    "    center_h = y_min + h/2\n",
    "    centerpoint = int(center_w * frame_w), int(center_h * frame_h)\n",
    "    # square size is max of width/length based on mediapipe bounding box + 10% more\n",
    "    face_size = max(w * frame_w, h * frame_h)\n",
    "    face_size = int(face_size + face_size*0.1)\n",
    "\n",
    "\n",
    "    # print(face_size) CAN BE DELTED\n",
    "\n",
    "    # square based on max frame_w or frame_h JUST TO CHECK IT IS CENTERED\n",
    "    # cv2.circle(frame, centerpoint, radius = 0, color = (255, 0, 255), thickness = 2)\n",
    "\n",
    "\n",
    "    # get the 4 corners of face\n",
    "    face_size_half = int(face_size/2)\n",
    "    tl = (centerpoint[0] - face_size_half, centerpoint[1] - face_size_half)\n",
    "    bl = (centerpoint[0] - face_size_half, centerpoint[1] + face_size_half)\n",
    "    tr = (centerpoint[0] + face_size_half, centerpoint[1] - face_size_half)\n",
    "    br = (centerpoint[0] + face_size_half, centerpoint[1] + face_size_half)\n",
    "    # Note that colors below are messed up because opencv uses BGR\n",
    "    cv2.circle(frame, tl, radius = 2, color = (0,0,255), thickness = 2)\n",
    "    cv2.circle(frame, bl, radius = 2, color = (0,255,0), thickness = 2)\n",
    "    cv2.circle(frame, tr, radius = 2, color = (255,0,0), thickness = 2)\n",
    "    cv2.circle(frame, br, radius = 2, color = (0,255,255), thickness = 2)\n",
    "\n",
    "    # CROP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('test.jpg')\n",
    "test_bbox = face_detector.get_bboxs(test)[0]\n",
    "face_detector.draw_bbox(test_bbox[0], test_bbox[1], test)\n",
    "get_face(test_bbox[1], test)\n",
    "# test_reshape = cv2.resize(test, (200,200))\n",
    "# test.shape\n",
    "cv2.imshow('hi',test)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ACTUAL\" THING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# model paths\n",
    "GENDER_MODEL_PATH = '../face/gender_model.hdf5'\n",
    "# get models\n",
    "\n",
    "gender_model = keras.models.load_model(GENDER_MODEL_PATH)\n",
    "# param is 0, first webcam in list of webcams\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while cam.isOpened():\n",
    "    # take frame from webcam\n",
    "    success, frame = cam.read()\n",
    "    # flip frame for selfie mode\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # check if loaded frame\n",
    "    if not success:\n",
    "        print(\"Image is donezo gonezo\")\n",
    "        continue\n",
    "\n",
    "    # frame setup\n",
    "    frame.flags.writeable = False # not writeable, pass by reference\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # rgb for mediapipe use\n",
    "    # detect boxes\n",
    "    bboxs = face_detector.get_bboxs(frame)\n",
    "\n",
    "    # draw bbox on frame\n",
    "    frame.flags.writeable = True # now need to draw on\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) # back to bgr for opencv\n",
    "\n",
    "    if bboxs:\n",
    "        for bbox in bboxs:\n",
    "            #Draw box on face\n",
    "            face_detector.draw_bbox(bbox[0], bbox[1], frame)\n",
    "\n",
    "    # display frame\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    # use q to quit\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# close the camera\n",
    "cam.release()\n",
    "# Close windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137b06e20b604b3c885ac65a4d38ed2264cdbd14f1bfcecdca2fd76b7a9afbc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('face': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
