{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import modules.mod_faceDetection as fd\n",
    "import sys\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules from sibling directory \"gender\"\n",
    "currentdir = os.getcwd()\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.append(parentdir +  os.path.sep + 'gender') # append gender directory to python path to allow module reading\n",
    "\n",
    "from gender_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_box(bbox_dict, frame):\n",
    "    x_min, y_min, w, h = bbox_dict.values()\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    # get centerpoint\n",
    "    center_w = x_min + w/2\n",
    "    center_h = y_min + h/2\n",
    "    centerpoint = int(center_w * frame_w), int(center_h * frame_h)\n",
    "    # square size is max of width/length based on mediapipe bounding box\n",
    "    face_size = max(w * frame_w, h * frame_h)\n",
    "    # face_size = int(face_size + face_size*0.1) # extend the face detection box by 10%\n",
    "    face_size = int(face_size)\n",
    "\n",
    "    # get the 4 corners of face, or clip to edge of image\n",
    "    face_size_half = int(face_size/2) # since we start with centerpoint\n",
    "\n",
    "    left = np.clip(centerpoint[0] - face_size_half, a_min=0, a_max=frame_w)\n",
    "    right = np.clip(centerpoint[0] + face_size_half, a_min=0, a_max=frame_w)\n",
    "    bottom = np.clip(centerpoint[1] + face_size_half, a_min = 0, a_max = frame_h)\n",
    "    top = np.clip(centerpoint[1] - face_size_half, a_min = 0, a_max = frame_h)\n",
    "\n",
    "    tl = (left, top)\n",
    "    bl = (left, bottom)\n",
    "    tr = (right, top)\n",
    "    br = (right, bottom)\n",
    "\n",
    "    # # Note that colors below are \"incorrect\" because opencv uses BGR\n",
    "    # cv2.circle(frame, tl, radius = 2, color = (0,0,255), thickness = 2)\n",
    "    # cv2.circle(frame, bl, radius = 2, color = (0,255,0), thickness = 2)\n",
    "    # cv2.circle(frame, tr, radius = 2, color = (255,0,0), thickness = 2)\n",
    "    # cv2.circle(frame, br, radius = 2, color = (0,255,255), thickness = 2)\n",
    "\n",
    "    # return topleft point and face_size, for use with cropping\n",
    "    return left, right, bottom, top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(left, right, bottom, top, frame):\n",
    "    return frame[top:bottom, left:right, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starts webcam thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "# load in our models\n",
    "# model paths\n",
    "GENDER_MODEL_PATH = '../gender/gender_model.hdf5'\n",
    "# get models\n",
    "gender_model = keras.models.load_model(GENDER_MODEL_PATH)\n",
    "\n",
    "# Initiate face detection model\n",
    "face_detector = fd.FaceDetection(model_selection = 0, threshold = 0.7)\n",
    "\n",
    "# param is 0, first webcam in list of webcams\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while cam.isOpened():\n",
    "    # take frame from webcam\n",
    "    success, frame = cam.read()\n",
    "    # flip frame for selfie mode\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # check if loaded frame\n",
    "    if not success:\n",
    "        print(\"Image is donezo gonezo\")\n",
    "        continue\n",
    "\n",
    "    # frame setup\n",
    "    frame.flags.writeable = False # not writeable, pass by reference, makes it faster\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # rgb for mediapipe use\n",
    "\n",
    "\n",
    "    # detect boxes\n",
    "    bboxs = face_detector.get_bboxs(frame)\n",
    "\n",
    "    # draw bbox on frame\n",
    "    frame.flags.writeable = True # now need to draw on\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) # back to bgr for opencv\n",
    "\n",
    "    if bboxs:\n",
    "        for bbox in bboxs:\n",
    "            # crop face for models\n",
    "            face_left, face_right, face_bottom, face_top = get_face_box(bbox[1], frame) # obtain lrbt for slicing the image\n",
    "            face_cropped = crop_face(face_left, face_right, face_bottom, face_top, frame) # crops the face\n",
    "            face_cropped = cv2.resize(face_cropped, (200, 200))\n",
    "\n",
    "            # predicts with models\n",
    "            gender_score = gender_model.predict(np.array([face_cropped]))[0][0]\n",
    "            gender = \"F\" if gender_score >= 0.5 else \"M\"\n",
    "\n",
    "            # write gender\n",
    "            face_detector.draw_bbox(bbox[0], bbox[1], frame, gender = gender, gender_score = gender_score)\n",
    "\n",
    "            #Draw box on face\n",
    "            # face_detector.draw_bbox(bbox[0], bbox[1], frame)\n",
    "\n",
    "    # display frame\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    # use q to quit\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# close the camera\n",
    "cam.release()\n",
    "# Close windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137b06e20b604b3c885ac65a4d38ed2264cdbd14f1bfcecdca2fd76b7a9afbc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('face': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
