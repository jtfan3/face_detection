{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from gender_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tf.data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_utk(file_path):\n",
    "  # obtain label\n",
    "  label = tf.strings.split(file_path, os.path.sep)[-2]\n",
    "  label = tf.strings.to_number(label, out_type=tf.dtypes.int32)\n",
    "  # label = tf.one_hot(label, 2) # for one hot encoding\n",
    "  label = tf.cast(label, dtype=tf.uint8)\n",
    "\n",
    "  # obtain image\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = tf.image.decode_jpeg(img)\n",
    "  img = tf.image.resize(img, IMG_SIZE)\n",
    "  img = img/255\n",
    "\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentations(image, label):\n",
    "  image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "  image = tf.image.random_hue(image, 0.05)\n",
    "  image = tf.image.random_brightness(image, 0.2)\n",
    "  image = tf.image.adjust_gamma(image, gamma=0.2, gain=0.2)\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "utk_ds = tf.data.Dataset.list_files(GENDER_DATA + '/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = len(utk_ds)\n",
    "# shuffle data for splitting\n",
    "utk_ds = utk_ds.shuffle(data_len, reshuffle_each_iteration=True)\n",
    "\n",
    "# split data\n",
    "val_len = int(data_len * VAL_SPLIT)\n",
    "train_ds = utk_ds.skip(val_len)\n",
    "val_ds = utk_ds.take(val_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(load_utk, num_parallel_calls=tf.data.AUTOTUNE).map(image_augmentations, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(load_utk, num_parallel_calls=tf.data.AUTOTUNE).cache().batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    layers.Conv2D(32, (2, 2), padding = \"same\", activation='relu', input_shape=IMG_SHAPE),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (2, 2), padding = \"same\", activation='relu'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (2,2), 2, activation='relu'),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), 2, activation='relu'),\n",
    "    # layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    # keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2), \n",
    "    # keras.layers.Dense(128, activation=\"relu\"),\n",
    "    # keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),    \n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                optimizer=\"Adam\", \n",
    "                metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "314/314 [==============================] - 34s 106ms/step - loss: 0.5232 - binary_accuracy: 0.7305 - val_loss: 0.3888 - val_binary_accuracy: 0.8304\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38884, saving model to ./models\\val_loss_0.389.hdf5\n",
      "Epoch 2/20\n",
      "314/314 [==============================] - 32s 102ms/step - loss: 0.3516 - binary_accuracy: 0.8454 - val_loss: 0.3352 - val_binary_accuracy: 0.8560\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38884 to 0.33519, saving model to ./models\\val_loss_0.335.hdf5\n",
      "Epoch 3/20\n",
      "314/314 [==============================] - 31s 98ms/step - loss: 0.3160 - binary_accuracy: 0.8614 - val_loss: 0.3030 - val_binary_accuracy: 0.8747\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33519 to 0.30302, saving model to ./models\\val_loss_0.303.hdf5\n",
      "Epoch 4/20\n",
      "314/314 [==============================] - 31s 99ms/step - loss: 0.2927 - binary_accuracy: 0.8753 - val_loss: 0.2770 - val_binary_accuracy: 0.8832\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30302 to 0.27703, saving model to ./models\\val_loss_0.277.hdf5\n",
      "Epoch 5/20\n",
      "314/314 [==============================] - 31s 99ms/step - loss: 0.2806 - binary_accuracy: 0.8810 - val_loss: 0.2607 - val_binary_accuracy: 0.8946\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27703 to 0.26074, saving model to ./models\\val_loss_0.261.hdf5\n",
      "Epoch 6/20\n",
      "314/314 [==============================] - 33s 105ms/step - loss: 0.2664 - binary_accuracy: 0.8864 - val_loss: 0.2868 - val_binary_accuracy: 0.8778\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.26074\n",
      "Epoch 7/20\n",
      "314/314 [==============================] - 32s 102ms/step - loss: 0.2539 - binary_accuracy: 0.8901 - val_loss: 0.2560 - val_binary_accuracy: 0.8915\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.26074 to 0.25603, saving model to ./models\\val_loss_0.256.hdf5\n",
      "Epoch 8/20\n",
      "314/314 [==============================] - 30s 95ms/step - loss: 0.2445 - binary_accuracy: 0.8956 - val_loss: 0.2570 - val_binary_accuracy: 0.8918\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25603\n",
      "Epoch 9/20\n",
      "314/314 [==============================] - 29s 94ms/step - loss: 0.2361 - binary_accuracy: 0.9014 - val_loss: 0.2467 - val_binary_accuracy: 0.8966\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25603 to 0.24671, saving model to ./models\\val_loss_0.247.hdf5\n",
      "Epoch 10/20\n",
      "314/314 [==============================] - 36s 115ms/step - loss: 0.2265 - binary_accuracy: 0.9052 - val_loss: 0.2323 - val_binary_accuracy: 0.9068\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24671 to 0.23227, saving model to ./models\\val_loss_0.232.hdf5\n",
      "Epoch 11/20\n",
      "314/314 [==============================] - 41s 132ms/step - loss: 0.2176 - binary_accuracy: 0.9088 - val_loss: 0.2601 - val_binary_accuracy: 0.8903\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.23227\n",
      "Epoch 12/20\n",
      "314/314 [==============================] - 47s 149ms/step - loss: 0.2139 - binary_accuracy: 0.9112 - val_loss: 0.2399 - val_binary_accuracy: 0.8943\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.23227\n",
      "Epoch 13/20\n",
      "314/314 [==============================] - 47s 150ms/step - loss: 0.2054 - binary_accuracy: 0.9133 - val_loss: 0.2296 - val_binary_accuracy: 0.9020\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.23227 to 0.22956, saving model to ./models\\val_loss_0.230.hdf5\n",
      "Epoch 14/20\n",
      "314/314 [==============================] - 45s 143ms/step - loss: 0.1938 - binary_accuracy: 0.9196 - val_loss: 0.2055 - val_binary_accuracy: 0.9173\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.22956 to 0.20549, saving model to ./models\\val_loss_0.205.hdf5\n",
      "Epoch 15/20\n",
      "314/314 [==============================] - 44s 139ms/step - loss: 0.1896 - binary_accuracy: 0.9217 - val_loss: 0.2237 - val_binary_accuracy: 0.9077\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20549\n",
      "Epoch 16/20\n",
      "314/314 [==============================] - 42s 135ms/step - loss: 0.1850 - binary_accuracy: 0.9240 - val_loss: 0.2063 - val_binary_accuracy: 0.9134\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20549\n",
      "Epoch 17/20\n",
      "314/314 [==============================] - 40s 126ms/step - loss: 0.1818 - binary_accuracy: 0.9228 - val_loss: 0.2039 - val_binary_accuracy: 0.9145\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.20549 to 0.20387, saving model to ./models\\val_loss_0.204.hdf5\n",
      "Epoch 18/20\n",
      "314/314 [==============================] - 37s 119ms/step - loss: 0.1699 - binary_accuracy: 0.9305 - val_loss: 0.1822 - val_binary_accuracy: 0.9224\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20387 to 0.18218, saving model to ./models\\val_loss_0.182.hdf5\n",
      "Epoch 19/20\n",
      "314/314 [==============================] - 39s 125ms/step - loss: 0.1620 - binary_accuracy: 0.9320 - val_loss: 0.1753 - val_binary_accuracy: 0.9298\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.18218 to 0.17534, saving model to ./models\\val_loss_0.175.hdf5\n",
      "Epoch 20/20\n",
      "314/314 [==============================] - 36s 113ms/step - loss: 0.1526 - binary_accuracy: 0.9367 - val_loss: 0.1862 - val_binary_accuracy: 0.9281\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a4e1a61c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "        # tf.keras.callbacks.TensorBoard(log_dir=LOG_PATH, histogram_freq=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(MODEL_PATH,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')]\n",
    "\n",
    "model.fit(train_ds, epochs=20, verbose = 1, callbacks = callbacks,\n",
    "         validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gender_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "137b06e20b604b3c885ac65a4d38ed2264cdbd14f1bfcecdca2fd76b7a9afbc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('face': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
